import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,b as t,o as n}from"./app-rNZLSKib.js";const l="/blog_postgraduate/assets/big_map_reduce-CAkclfUY.png",e="/blog_postgraduate/assets/filter-Css19ZOe.jpg",h="/blog_postgraduate/assets/finance_1-W9EeRozz.png",p="/blog_postgraduate/assets/suppl_module-DfzjZ9Zu.png",r={};function k(d,i){return n(),a("div",null,i[0]||(i[0]=[t('<h1 id="课程-大数据决策分析与决策" tabindex="-1"><a class="header-anchor" href="#课程-大数据决策分析与决策"><span>课程-大数据决策分析与决策</span></a></h1><blockquote><p>2025年9月7日 第一节课<br> 大数据分析和决策<br> 助教：<br> 老师: 陈涛</p><p>本课能学到</p><ul><li>了解金融大数据的基本概念和相关理论知识</li><li>1、金融大数据知识简介</li><li>2、金融大数据理论基础</li><li>3、python基础</li><li>4、金融场景下的python</li><li>5、python金融分析</li><li>6、深度学习大数据分析</li><li>7、经典案例分析和实践</li></ul><p>考核要求： 不考试 <br> 考勤、课堂表现(讨论和发言) 10% <br> 作业 20 <br> 课程报告 70% <br></p></blockquote><h2 id="第一次课" tabindex="-1"><a class="header-anchor" href="#第一次课"><span>第一次课</span></a></h2><p>2025年9月7日</p><h3 id="大数据背景简介" tabindex="-1"><a class="header-anchor" href="#大数据背景简介"><span>大数据背景简介</span></a></h3><p>大数据特点：<br> 1、体量巨大。2025年，全球年新增数据量达到175ZB<br> 2、数据类型。多样化和非机构化<br> 3、处理速度快。从复杂数据中获取高价值信息。<br> 4、价值密度低。</p><p>计算方式：<br> 1、云计算<br> 2、分布式系统（核心map和reduce）<br><img src="'+l+'" alt="img_1.png" loading="lazy"></p><p>3、数据挖掘<br> 借助算法从海量信息中挖掘有价值信息活动<br><img src="'+e+'" alt="img.png" loading="lazy"></p><p>大数据挑战:<br> 1、网络架构</p><p>2、数据中心<br> 为啥大数据在贵州等中西部地区？<br> 地皮便宜、电费便宜<br> 数据丢失<br> 数据安全</p><p>3、运维的挑战</p><h3 id="金融大数据简介" tabindex="-1"><a class="header-anchor" href="#金融大数据简介"><span>金融大数据简介</span></a></h3><p>金融行业是典型的数据驱动行业，每天产生大量数据，包括交易、报价、业绩报告等各种指标数据</p><figure><img src="'+h+'" alt="img_1.png" tabindex="0" loading="lazy"><figcaption>img_1.png</figcaption></figure><p>金融数据产生主题： 人、物、机器</p><figure><img src="'+p+`" alt="img_1.png" tabindex="0" loading="lazy"><figcaption>img_1.png</figcaption></figure><h3 id="银行大数据应用场景" tabindex="-1"><a class="header-anchor" href="#银行大数据应用场景"><span>银行大数据应用场景</span></a></h3><h4 id="银行大数据核心应用场景及具体描述" tabindex="-1"><a class="header-anchor" href="#银行大数据核心应用场景及具体描述"><span>银行大数据核心应用场景及具体描述</span></a></h4><ol><li><p><strong>信贷风控：筑牢风险防线</strong><br> 基于客户多维度数据（如征信记录、交易流水、资产负债情况、行为偏好等）构建智能风控模型，实现贷前精准画像——快速识别高风险客户，避免“带病授信”； 贷中动态监测——实时追踪客户资金流向与还款能力变化，预警逾期风险；贷后高效处置——通过数据关联分析定位失联客户、评估资产处置价值，大幅降低不良贷款率， 提升信贷业务安全性。</p></li><li><p><strong>精准营销：提升客户价值</strong><br> 整合客户基础信息（年龄、职业、地域）、交易数据（消费类型、频次、额度）、互动行为（APP点击、咨询记录）等数据，搭建客户分层体系与需求标签库。 针对不同客群推送定制化服务：如为高频消费客户推荐信用卡分期优惠，为高净值客户匹配财富管理产品，为小微企业主推送经营性贷款方案，实现“千人千策”的营销触达， 提升转化率与客户黏性。</p></li><li><p><strong>供应链金融：激活产业链活力</strong><br> 打通核心企业、上下游中小企业与银行的数据链路，依托核心企业的信用背书与供应链交易数据（如订单合同、物流信息、应收账款凭证等），为链条上的中小企业 提供无抵押、高效率的融资服务。例如，基于真实的应收账款数据为上游供应商提供“保理融资”，基于订单数据为下游经销商提供“订单贷”，解决中小企业融资难、 融资慢的痛点，同时降低银行信贷风险，助力产业链稳定运转。</p></li><li><p><strong>运营优化：降本增效提体验</strong><br> 通过大数据分析优化银行内部运营与客户服务流程：在网点运营上，分析客户到访高峰时段与业务办理类型，动态调整窗口数量与人员排班，减少客户等待时间； 在线上服务上，基于客户咨询热点数据优化APP功能布局、完善智能客服知识库，提升自助服务效率；在成本控制上，分析各业务线的资金占用、人力投入与收益情况， 优化资源配置，砍掉低效业务环节，实现“降本、增效、提质”的运营目标。</p></li></ol><p>5<strong>保险、证券</strong></p><h3 id="重点" tabindex="-1"><a class="header-anchor" href="#重点"><span>重点</span></a></h3><p>业务代码翻译渐渐被AI替代，未来会越来越难受<br> 电商跨界金融给传统金融造成交大冲击（信用卡），因此，以银行为代表金融机构接到电商寻求新出路（一方面搭建自己电商、一方面和电商合作）。</p><h2 id="第二次课" tabindex="-1"><a class="header-anchor" href="#第二次课"><span>第二次课</span></a></h2><p>2025年9月14日<br> 大数据分析是指适当的统计分析方法对采集的大数据进行分析，并将这些数据加以汇总、理解和消化，提取有用的信息和形成结论，以求最大化的开发数据的功能和发挥 数据的作用。</p><h3 id="大数据分析方法类型" tabindex="-1"><a class="header-anchor" href="#大数据分析方法类型"><span>大数据分析方法类型</span></a></h3><p>1、描述性分析<br> 描述性分析是指对数据进行描述，如数据的基本统计信息、数据的分布、数据的关系、数据的分布等。<br> 2、预测性分析<br> 预测性分析是指利用历史数据和统计模型，对未来事件或结果进行预测。<br> 3、规范性分析<br> 正规性分析是指对数据进行正则化，将数据进行转换，使其符合正态分布，从而提高数据的处理效率。<br> 4、关联规则分析<br> 关联规则分析是指对数据进行关联，找出数据之间的关联关系，从而找出数据之间的 dependencies。<br> 5、聚类分析<br> 聚类分析是指对数据进行聚类(分到未知类别)，将数据进行分类，从而找出数据之间的 dependencies。<br> 6、分类分析<br> 分类分析是指对数据进行分类(分到已知类别)，将数据进行分类，从而找出数据之间的 dependencies。<br> 7、时间序列分析<br> 时间序列分析是指对时间序列数据进行分析，如数据的趋势、季节性、周期性等。<br> 8、数据挖掘<br> 数据挖掘是指从大量数据中提取隐藏的模式、关联规则、趋势和异常值等信息的过程。它通常用于发现数据中的隐藏结构和知识，帮助组织做出更明智的决策。<br> 数据挖掘技术包括关联规则挖掘、聚类分析、分类分析、决策树挖掘、神经网络挖掘等。</p><p>依据探索自然过程，可以划分为定性分析和定量分析，定型分析侧重于模物理模型的建立和数据意义的阐述；定量分析为信息研究提供数据依据，侧重于数学模型 的建立和求解。二者相互补充。</p><h3 id="大数据分析方法的步骤" tabindex="-1"><a class="header-anchor" href="#大数据分析方法的步骤"><span>大数据分析方法的步骤</span></a></h3><p>1、数据的获取存贮<br> 2、数据信息抽取和无用信息清洗<br> 3、数据整合和表述<br> 4、数据模型建立和结果分析<br> 5、结果阐述</p><h3 id="大数据预处理" tabindex="-1"><a class="header-anchor" href="#大数据预处理"><span>大数据预处理</span></a></h3><p>大数据预处理是数据分析和机器学习流程中至关重要的一步。它的目标是将原始、杂乱、不完整或含有噪声的数据，转化为<strong>干净、一致、适合分析或建模的格式</strong>。如果跳过这一步，后续的分析结果可能会严重失真。</p><blockquote><p>💡 <strong>核心原则</strong>：<br><strong>“垃圾进，垃圾出”（Garbage In, Garbage Out）</strong><br> 再强大的模型也救不了脏数据。</p></blockquote><hr><h4 id="一、大数据预处理的主要步骤" tabindex="-1"><a class="header-anchor" href="#一、大数据预处理的主要步骤"><span>一、大数据预处理的主要步骤</span></a></h4><h5 id="_1-数据清洗-data-cleaning" tabindex="-1"><a class="header-anchor" href="#_1-数据清洗-data-cleaning"><span>1. 数据清洗（Data Cleaning）</span></a></h5><p>处理数据中的“脏”部分。</p><ul><li><strong>处理缺失值</strong>： <ul><li>删除含有缺失值的记录（适用于缺失少的情况）</li><li>填补缺失值：用均值、中位数、众数、插值法，或机器学习预测填补</li></ul></li><li><strong>处理异常值（Outliers）</strong>： <ul><li>使用箱线图、Z-score、IQR 等方法识别并处理</li><li>可选择删除、修正或保留（取决于业务背景）</li></ul></li><li><strong>去重</strong>： <ul><li>删除重复的记录（如用户多次提交相同信息）</li></ul></li></ul><hr><h5 id="_2-数据集成-data-integration" tabindex="-1"><a class="header-anchor" href="#_2-数据集成-data-integration"><span>2. 数据集成（Data Integration）</span></a></h5><p>将来自多个数据源的数据整合在一起。</p><ul><li>合并数据库、日志文件、API 数据等</li><li>处理<strong>模式冲突</strong>（如字段名不同）、<strong>单位不一致</strong>（如“公斤” vs “磅”）</li><li>避免冗余和矛盾信息</li></ul><blockquote><p>⚠️ <strong>挑战</strong>：大数据环境下，数据来源多、格式异构（结构化、半结构化、非结构化）</p></blockquote><hr><h5 id="_3-数据变换-data-transformation" tabindex="-1"><a class="header-anchor" href="#_3-数据变换-data-transformation"><span>3. 数据变换（Data Transformation）</span></a></h5><p>将数据转换为更适合分析的形式。</p><ul><li><strong>归一化（Normalization）</strong>： <ul><li>将数值缩放到 <code>[0,1]</code> 或 <code>[-1,1]</code> 区间，常用在神经网络等模型中</li><li>公式：<code>x&#39; = (x - min) / (max - min)</code></li></ul></li><li><strong>标准化（Standardization）</strong>： <ul><li>转换为均值为0、标准差为1的分布</li><li>公式：<code>x&#39; = (x - μ) / σ</code></li></ul></li><li><strong>离散化（Discretization）</strong>： <ul><li>将连续变量转为分类变量，如年龄分为“青年、中年、老年”</li></ul></li><li><strong>属性构造（Feature Engineering）</strong>： <ul><li>创建新特征，如从“出生日期”计算“年龄”</li></ul></li></ul><hr><h5 id="_4-数据规约-data-reduction" tabindex="-1"><a class="header-anchor" href="#_4-数据规约-data-reduction"><span>4. 数据规约（Data Reduction）</span></a></h5><p>在不损失关键信息的前提下，减少数据量，提高处理效率。</p><ul><li><strong>维度规约</strong>： <ul><li>主成分分析（PCA）、特征选择等，降低特征数量</li></ul></li><li><strong>数量规约</strong>： <ul><li>聚合、抽样（如随机抽样、分层抽样）、数据压缩</li></ul></li><li><strong>数值规约</strong>： <ul><li>用参数模型（如回归）或非参数方法（如直方图）近似表示数据</li></ul></li></ul><hr><h5 id="_5-数据编码-data-encoding" tabindex="-1"><a class="header-anchor" href="#_5-数据编码-data-encoding"><span>5. 数据编码（Data Encoding）</span></a></h5><p>将非数值数据转换为数值形式，便于算法处理。</p><ul><li><strong>标签编码（Label Encoding）</strong>： <ul><li>如：男 → 0，女 → 1</li></ul></li><li><strong>独热编码（One-Hot Encoding）</strong>： <ul><li>将类别变量转为多个二进制列（避免引入错误的顺序关系）</li><li>示例： <ul><li>红 → <code>[1, 0, 0]</code></li><li>绿 → <code>[0, 1, 0]</code></li><li>蓝 → <code>[0, 0, 1]</code></li></ul></li></ul></li></ul><hr><h4 id="二、大数据预处理的挑战" tabindex="-1"><a class="header-anchor" href="#二、大数据预处理的挑战"><span>二、大数据预处理的挑战</span></a></h4><table><thead><tr><th>挑战</th><th>说明</th></tr></thead><tbody><tr><td><strong>数据量大（Volume）</strong></td><td>处理TB/PB级数据，传统工具无法胜任</td></tr><tr><td><strong>数据种类多（Variety）</strong></td><td>结构化（表格）、半结构化（JSON）、非结构化（文本、图像）混合</td></tr><tr><td><strong>速度快（Velocity）</strong></td><td>实时流数据需要在线预处理</td></tr><tr><td><strong>质量差（Veracity）</strong></td><td>数据噪声多、缺失严重、格式混乱</td></tr><tr><td><strong>工具选择</strong></td><td>需使用分布式框架（如Spark、Flink）</td></tr></tbody></table><hr><h4 id="三、常用工具与技术" tabindex="-1"><a class="header-anchor" href="#三、常用工具与技术"><span>三、常用工具与技术</span></a></h4><table><thead><tr><th>工具/平台</th><th>用途</th></tr></thead><tbody><tr><td><code>Python</code>（Pandas, NumPy, Scikit-learn）</td><td>小到中等规模数据预处理</td></tr><tr><td><code>Apache Spark</code>（PySpark/Scala）</td><td>分布式大数据清洗与转换</td></tr><tr><td><code>Hadoop + Hive</code></td><td>批量数据清洗与查询</td></tr><tr><td><code>Apache Flink</code></td><td>实时流数据预处理</td></tr><tr><td><code>OpenRefine</code></td><td>交互式数据清洗工具</td></tr><tr><td><code>SQL</code></td><td>常用于过滤、聚合、去重等操作</td></tr></tbody></table><hr><h4 id="四、一个简单示例-python-pandas" tabindex="-1"><a class="header-anchor" href="#四、一个简单示例-python-pandas"><span>四、一个简单示例（Python + Pandas）</span></a></h4><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" data-title="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pandas </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> numpy </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 读取数据</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> pd.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">read_csv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;data.csv&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 1. 处理缺失值</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">fillna</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">mean</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">numeric_only</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">), </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">inplace</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 数值列用均值填充</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">dropna</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">subset</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;name&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">inplace</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)            </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 关键字段为空则删除</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 2. 去重</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">drop_duplicates</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">inplace</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 3. 处理异常值（以收入为例）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">Q1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">quantile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.25</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">Q3 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">quantile</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.75</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;">IQR</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> =</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Q3 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Q1</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">lower_bound </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Q1 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1.5</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> IQR</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">upper_bound </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> Q3 </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 1.5</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;"> *</span><span style="--shiki-light:#383A42;--shiki-dark:#D19A66;"> IQR</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[(df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&gt;=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> lower_bound) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&amp;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">&lt;=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> upper_bound)]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 4. 数据标准化</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income_scaled&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> (df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">-</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">mean</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">/</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;income&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">std</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 5. 类别编码</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;gender&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">] </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> df[</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;gender&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">map</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">({</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;男&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;女&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">})</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 输出清洗后数据</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">df.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">to_csv</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;cleaned_data.csv&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">index</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">False</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="第三次课" tabindex="-1"><a class="header-anchor" href="#第三次课"><span>第三次课</span></a></h2>`,64)]))}const c=s(r,[["render",k],["__file","course_data_analysis.html.vue"]]),A=JSON.parse('{"path":"/note/postgraduate/course_data_analysis.html","title":"课程-大数据决策分析与决策","lang":"zh-CN","frontmatter":{"icon":"form","date":"2025-09-07T00:00:00.000Z","category":"课程-大数据决策分析与决策","tag":["课程"],"description":"课程-大数据决策分析与决策 2025年9月7日 第一节课 大数据分析和决策 助教： 老师: 陈涛 本课能学到 了解金融大数据的基本概念和相关理论知识 1、金融大数据知识简介 2、金融大数据理论基础 3、python基础 4、金融场景下的python 5、python金融分析 6、深度学习大数据分析 7、经典案例分析和实践 考核要求： 不考试 考勤、课堂...","head":[["meta",{"property":"og:url","content":"https://liaorenhua.github.io/blog_postgraduate/blog_postgraduate/note/postgraduate/course_data_analysis.html"}],["meta",{"property":"og:site_name","content":"𝓛𝓮𝓸 𝓑𝓛𝓸𝓖"}],["meta",{"property":"og:title","content":"课程-大数据决策分析与决策"}],["meta",{"property":"og:description","content":"课程-大数据决策分析与决策 2025年9月7日 第一节课 大数据分析和决策 助教： 老师: 陈涛 本课能学到 了解金融大数据的基本概念和相关理论知识 1、金融大数据知识简介 2、金融大数据理论基础 3、python基础 4、金融场景下的python 5、python金融分析 6、深度学习大数据分析 7、经典案例分析和实践 考核要求： 不考试 考勤、课堂..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-09-14T11:41:00.000Z"}],["meta",{"property":"article:tag","content":"课程"}],["meta",{"property":"article:published_time","content":"2025-09-07T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-09-14T11:41:00.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"课程-大数据决策分析与决策\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-09-07T00:00:00.000Z\\",\\"dateModified\\":\\"2025-09-14T11:41:00.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Leo\\",\\"url\\":\\"https://liaorenhua.github.io/blog_postgraduate/\\"}]}"],["link",{"rel":"alternate","type":"application/atom+xml","href":"https://liaorenhua.github.io/blog_postgraduate/blog_postgraduate/atom.xml","title":"𝓛𝓮𝓸 𝓑𝓛𝓸𝓖 Atom Feed"}],["link",{"rel":"alternate","type":"application/json","href":"https://liaorenhua.github.io/blog_postgraduate/blog_postgraduate/feed.json","title":"𝓛𝓮𝓸 𝓑𝓛𝓸𝓖 JSON Feed"}],["link",{"rel":"alternate","type":"application/rss+xml","href":"https://liaorenhua.github.io/blog_postgraduate/blog_postgraduate/rss.xml","title":"𝓛𝓮𝓸 𝓑𝓛𝓸𝓖 RSS Feed"}]]},"headers":[{"level":2,"title":"第一次课","slug":"第一次课","link":"#第一次课","children":[{"level":3,"title":"大数据背景简介","slug":"大数据背景简介","link":"#大数据背景简介","children":[]},{"level":3,"title":"金融大数据简介","slug":"金融大数据简介","link":"#金融大数据简介","children":[]},{"level":3,"title":"银行大数据应用场景","slug":"银行大数据应用场景","link":"#银行大数据应用场景","children":[]},{"level":3,"title":"重点","slug":"重点","link":"#重点","children":[]}]},{"level":2,"title":"第二次课","slug":"第二次课","link":"#第二次课","children":[{"level":3,"title":"大数据分析方法类型","slug":"大数据分析方法类型","link":"#大数据分析方法类型","children":[]},{"level":3,"title":"大数据分析方法的步骤","slug":"大数据分析方法的步骤","link":"#大数据分析方法的步骤","children":[]},{"level":3,"title":"大数据预处理","slug":"大数据预处理","link":"#大数据预处理","children":[]}]},{"level":2,"title":"第三次课","slug":"第三次课","link":"#第三次课","children":[]}],"git":{"createdTime":1757219527000,"updatedTime":1757850060000,"contributors":[{"name":"leo","username":"leo","email":"993929808@qq.com","commits":13,"url":"https://github.com/leo"}]},"readingTime":{"minutes":9.27,"words":2781},"filePathRelative":"note/postgraduate/course_data_analysis.md","localizedDate":"2025年9月7日","excerpt":"","autoDesc":true}');export{c as comp,A as data};
